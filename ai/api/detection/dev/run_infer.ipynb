{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 단일 이미지 추론\n",
    "- `detect.py`를 사용할 경우 [YOLOv5](https://github.com/ultralytics/yolov5)를 clone 받고 해당 레포지토리에서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# GPU가 사용 가능한 경우 cuda 사용 / GPU가 사용 불가능한 경우 CPU로 초기화하여 CPU 사용\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전처리 함수\n",
    "def preprocess_image(image, image_size, crop_size, interpolation=Image.LANCZOS):\n",
    "    '''\n",
    "    Parameters\n",
    "    - image: (PIL.JpegImagePlugin.JpegImageFile) 이미지 파일\n",
    "    - image_size: (int) yolo input 이미지 사이즈\n",
    "    - crop_size: (list, tuple) \"좌-상-우-하\" 순서로 자를 길이\n",
    "    - interpolation: (int) interpolation 방식 / default: Image.LANCZOS\n",
    "    '''\n",
    "\n",
    "    # 이미지 crop -> 정사각형으로 만들기\n",
    "    image_width, image_height = image.size\n",
    "    cropped = image.crop((crop_size[0], crop_size[1], image_width-crop_size[2], image_height-crop_size[3]))\n",
    "\n",
    "    # resize\n",
    "    resized = cropped.resize((image_size, image_size), interpolation)\n",
    "    b = BytesIO()\n",
    "    resized.save(b, 'jpeg')\n",
    "    return Image.open(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 이름\n",
    "image_name = 'wheel.jpg'\n",
    "\n",
    "# 이미지 load\n",
    "image = Image.open('folder_name/' + image_name)\n",
    "\n",
    "# 전처리 수행\n",
    "image = preprocess_image(image, 2048, (200, 0, 200, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-163-g016e046 Python-3.9.13 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\SSAFY\\dev\\pjt3\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 346 layers, 76126356 parameters, 0 gradients, 109.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "## 모델 ##\n",
    "\n",
    "model = torch.hub.load('.', 'custom','weights/best_0511.pt', source='local')\n",
    "\n",
    "# confidence를 높여서 더욱 정밀하게 추론하도록 만듦\n",
    "model.conf = 0.7\n",
    "\n",
    "# 하나의 bbox에 대해 여러 라벨을 할당하지 못하도록 만듦\n",
    "model.multi_label = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추론 ##\n",
    "results = model(image, size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns\\detect\\exp10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 추론 결과\n",
    "# results.show()              # 추론 이미지 보기\n",
    "# results.save()              # 추론 이미지 저장\n",
    "\n",
    "# bbox x좌측좌표/y위쪽좌표/x오른쪽좌표/y아래좌표 데이터 저장\n",
    "bolts = results.xyxy[0].tolist()\n",
    "\n",
    "# bbox x중앙좌표/y중앙좌표/가로/세로 데이터(normalized) 저장\n",
    "bolts_norm = results.xywhn[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확장자 제거\n",
    "image_name_revised = image_name.replace('.jpg', '')\n",
    "\n",
    "# 볼트 이미지 저장 폴더\n",
    "bolt_folder = 'bolt_images/'\n",
    "\n",
    "# 볼트 좌표를 저장할 텍스트 파일 열기\n",
    "with open('{} + {}'.format(bolt_folder, image_name_revised) + '.txt', 'w') as f:\n",
    "    for idx, bolt in enumerate(bolts):\n",
    "        # x좌측좌표/y위쪽좌표/x오른쪽좌표/y아래좌표\n",
    "        x_min, y_min, x_max, y_max = list(map((lambda x: x.item()), bolt[:4]))\n",
    "        \n",
    "        # 볼트 이미지 crop\n",
    "        cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "        \n",
    "        # 볼트 이미지 저장\n",
    "        cropped.save(bolt_folder + '{}_{}.jpg'.format(image_name_revised, idx+1))\n",
    "\n",
    "        # yolo 라벨(label) 형식에 맞게 텍스트 작성\n",
    "        bbox_str = '{} {} {} {} {}'.format(int(bolts_norm[idx][-1]), bolts_norm[idx][0], bolts_norm[idx][1], bolts_norm[idx][2], bolts_norm[idx][3])\n",
    "        f.write(bbox_str + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\SSAFY\\dev\\pjt3\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['weights/best_0511.pt'], source=datasets/test_presentation/lost_0508_27.jpg, data=data\\coco128.yaml, imgsz=[2048, 2048], conf_thres=0.89, iou_thres=0.45, max_det=1000, device=cuda:0, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=results/test_0517, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-163-g016e046 Python-3.9.13 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "image 1/1 C:\\Users\\SSAFY\\dev\\pjt3\\yolov5\\datasets\\test_presentation\\lost_0508_27.jpg: 1728x2048 3 inners, 8 outers, 104.4ms\n",
      "Speed: 3.7ms pre-process, 104.4ms inference, 67.8ms NMS per image at shape (1, 3, 2048, 2048)\n",
      "Results saved to \u001b[1mresults\\test_0517\\exp\u001b[0m\n",
      "1 labels saved to results\\test_0517\\exp\\labels\n"
     ]
    }
   ],
   "source": [
    "## detect.py 파일로 추론 수행 ##\n",
    "\n",
    "# # Hyperparameters\n",
    "# image_size = 2048                       # 이미지 사이즈\n",
    "# image_path = 'wheel.jpg'                # 추론 대상 이미지\n",
    "# data_path = 'data/wheel.yaml'           # data 파일\n",
    "# weights_path = 'weights/yolo_0511.pt'   # weight 파일\n",
    "# save_path = 'results/test'              # 추론 결과 저장 폴더\n",
    "# conf_thres = 0.89                       # confidence threshold\n",
    "# device = torch.device(\"cuda:0\")         # 추론에 사용할 device\n",
    "\n",
    "# !python detect.py --weights {weights_path} --img {image_size} --conf {conf_thres} --source {image_path} --project {save_path} --device {device} --save-txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 여러 이미지 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS ##\n",
    "\n",
    "MODEL_PATH = 'weights/'                             # weights 폴더\n",
    "MODEL_NAME = 'yolo_0511.pt'                         # weights 파일 이름\n",
    "IMAGE_PATH = 'images/'                              # 추론 대상 이미지들이 있는 폴더\n",
    "IMAGE_SIZE = 2048                                   # 이미지 사이즈\n",
    "CROP_SIZE = (200, 0, 200, 0)                        # 전처리 시 수행할 크롭 사이즈(좌, 상, 우, 하)\n",
    "BOLT_IMAGE_PATH = 'bolt_images/'                    # 볼트 이미지를 저장할 폴더\n",
    "CONFIDENCE = 0.95                                   # confidence threshold\n",
    "MULTI_LABEL = False                                 # multi label 비허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-163-g016e046 Python-3.9.13 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\SSAFY\\dev\\pjt3\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "## 모델\n",
    "model = torch.hub.load('.', 'custom',MODEL_PATH + MODEL_NAME, source='local')\n",
    "\n",
    "# confidence를 높여서 더욱 정밀하게 추론하도록 만듦\n",
    "model.conf = CONFIDENCE\n",
    "\n",
    "# 하나의 bbox에 대해 여러 라벨을 할당하지 못하도록 만듦\n",
    "model.multi_label = MULTI_LABEL\n",
    "\n",
    "\n",
    "## 전처리 함수\n",
    "def preprocess_image(image, image_size, crop_size, interpolation=Image.LANCZOS):\n",
    "    '''\n",
    "    Parameters\n",
    "    - image: (PIL.JpegImagePlugin.JpegImageFile) 이미지 파일\n",
    "    - image_size: (int) yolo input 이미지 사이즈\n",
    "    - crop_size: (list, tuple) \"좌-상-우-하\" 순서로 자를 길이\n",
    "    - interpolation: (int) interpolation 방식 / default: Image.LANCZOS\n",
    "    '''\n",
    "\n",
    "    # 이미지 crop -> 정사각형으로 만들기\n",
    "    image_width, image_height = image.size\n",
    "    cropped = image.crop((crop_size[0], crop_size[1], image_width-crop_size[2], image_height-crop_size[3]))\n",
    "\n",
    "    # resize\n",
    "    resized = cropped.resize((image_size, image_size), interpolation)\n",
    "    b = BytesIO()\n",
    "    resized.save(b, 'jpeg')\n",
    "    return Image.open(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "## 추론할 이미지 정의 ##\n",
    "\n",
    "# 이미지 폴더에는 반드시 이미지만 넣을 것\n",
    "image_folder = IMAGE_PATH\n",
    "image_list = os.listdir(image_folder)\n",
    "\n",
    "if '.ipynb_checkpoints' in image_list:\n",
    "    image_list.remove('.ipynb_checkpoints')\n",
    "\n",
    "# print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in image_list:\n",
    "    image = Image.open(image_folder + image_name)\n",
    "    image = preprocess_image(image, IMAGE_SIZE, CROP_SIZE)\n",
    "\n",
    "    results = model(image, size=IMAGE_SIZE)\n",
    "    bolts = results.xyxy[0].tolist()\n",
    "    bolts_norm = results.xywhn[0].tolist()\n",
    "\n",
    "    image_name_revised = image_name.replace('.jpg', '')\n",
    "    with open(BOLT_IMAGE_PATH + '{}.txt'.format(image_name_revised), 'w') as f:\n",
    "        for idx, bolt in enumerate(bolts):\n",
    "            x_min, y_min, x_max, y_max = list(map((lambda x: x.item()), bolt[:4]))\n",
    "            cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "            cropped.save(BOLT_IMAGE_PATH + '{}_{}.jpg'.format(image_name_revised, idx+1))\n",
    "\n",
    "            bbox_str = '{} {} {} {} {}'.format(int(bolts_norm[idx][-1]), bolts_norm[idx][0], bolts_norm[idx][1], bolts_norm[idx][2], bolts_norm[idx][3])\n",
    "            f.write(bbox_str + '\\n')\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
