{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SEMES] - 볼트 이상진단 - 전이학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전이학습 - 학습을 진행할 때 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 파이토치의 핵심 패키지(모델 구성 및 학습 등을 수행할 수 있는 기능을 제공)\n",
    "import torch\n",
    "# PyTorch에서 제공하는 신경망 모듈\n",
    "import torch.nn as nn\n",
    "# 학습에 사용되는 최적화 알고리즘\n",
    "import torch.optim as optim\n",
    "# PyTorch에서 이미지 데이터 처리와 관련된 함수와 모델들을 제공\n",
    "from torchvision import models, datasets\n",
    "# transforms 모듈은 데이터 전처리를 위한 함수들을 제공\n",
    "import torchvision.transforms as transforms\n",
    "# DataLoader를 이용하여 데이터셋에서 미니배치(minibatch)를 추출 \n",
    "from torch.utils.data import DataLoader\n",
    "# 시간과 관련된 함수를 제공\n",
    "import time\n",
    "\n",
    "\n",
    "# 그래프 - 데이터 시각화를 위해 그래프나 도형을 화면에 출력해줌\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# 컨퓨전 매트릭스 - sklearn.metrics == 평가 지표를 계산하는 패키지 \n",
    "# 컨퓨전 매트릭스 - classification_report == 분류 모델을 평가한 후 각 클래스마다 지표를 출력(정확도(Accuracy)0/밀도(Precision)/재현율(Recall)/F1-점수(F1-Score)/지원 개수(Support)\n",
    "# f1 score - f1_score == 분류 모델을 평가하는 지표- 정밀도(precision)와 재현율(recall)의 조화평균(정확도와 유사하지만 불균형한 데이터에서도 적절한지 평가할 수 있는 지표가 됨)\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# 컨퓨전 매트릭스 - 데이터 시각화 라이브러리\n",
    "import seaborn as sns\n",
    "\n",
    "# 평가코드\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전이학습 - GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU가 사용 가능한 경우 cuda 사용 / GPU가 사용 불가능한 경우 CPU로 초기화하여 CPU 사용\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU instead.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전이학습 - 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터 전처리\n",
    "train_transform = transforms.Compose([\n",
    "    # 해상도를 (224,224)로 맞춰준다 (a fixed resolution of 224×224 is best, even at higher flops : [논문]Designing Network Design Spaces - [저자]Facebook AI Research (FAIR))\n",
    "    transforms.Resize((224, 224)),\n",
    "    # 이미지를 좌우로 뒤집어서 데이터 증강(augmentation)을 수행(확률을 높여준)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 이미지를 PyTorch의 Tensor로 변환\n",
    "    transforms.ToTensor(),\n",
    "    # 흑백 이미지이기 때문에 1개의 채널을 정규화(흑백이미지는 보통 (평균 : 0.5 / 표준편차 : 0.5)로 정규화)\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "# 테스트데이터 전처리\n",
    "test_transform = transforms.Compose([\n",
    "    # 해상도를 (224,224)로 맞춰준다\n",
    "    transforms.Resize((224, 224)),\n",
    "    # 이미지를 PyTorch의 Tensor로 변환\n",
    "    transforms.ToTensor(),\n",
    "    # 흑백 이미지이기 때문에 1개의 채널을 정규화\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "# 데이터가 저장된 경로\n",
    "data_dir = './semes_transfer'\n",
    "print(os.path.join(data_dir, 'train'))\n",
    "\n",
    "# 데이터가 저장된 경로에서 ImageFolder를 이용하여 이미지 데이터셋을 전처리한 후 로드(transforms_*==전처리 수행)\n",
    "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), train_transform)\n",
    "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'val'), test_transform)\n",
    "\n",
    "# DataLoader를 이용 / 데이터셋에서 미니배치(minibatch)를 추출 \n",
    "# (batch_size==미니배치의 크기 / shuffle==데이터셋을 섞을지 여부 / num_workers==데이터셋을 불러올 때 사용할 프로세스 수)\n",
    "train_loader = DataLoader(train_datasets, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_datasets, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "# 수행 결과를 출력\n",
    "print('학습 데이터셋 크기:', len(train_datasets))\n",
    "print('테스트 데이터셋 크기:', len(test_datasets))\n",
    "\n",
    "# 학습된 클래스 이름과 수행 결과를 출력\n",
    "class_names = train_datasets.classes\n",
    "print('클래스:', class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전이학습 - 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "CLASSIFICATION_MODEL_DIR = os.path.join(os.path.join(BASE_DIR, \"models\"), \"classification_model.pth\")\n",
    "model = torch.load(CLASSIFICATION_MODEL_DIR)\n",
    "\n",
    "# 불러온 네트워크 모델의 출력 뉴런 수를 저장\n",
    "num_features = model.fc.in_features\n",
    "# 새로운 Fully Connected 레이어 추가\n",
    "model.fc = nn.Linear(num_features, 4)\n",
    "\n",
    "# GPU를 사용하기 위해 모델을 CUDA 디바이스로 보냄\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수와 최적화 알고리즘 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전이학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 epochs 설정\n",
    "num_epochs = '설정값'\n",
    "\n",
    "# epoch에 따른 손실 값과 정확도를 저장하는 리스트\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 최적 모델\n",
    "best_loss = '현재 모델의 loss'\n",
    "best_loss_epoch = 0\n",
    "\n",
    "best_acc = '현재 모델의 정확도'\n",
    "best_acc_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재시간 저장\n",
    "start_time = time.time()\n",
    "\n",
    "# 설정한 epochs 만큼 반복\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Train --------------------------------------------------------------------\n",
    "    # 모델을 학습모드로 설정\n",
    "    model.train()\n",
    "    # 현재까지 누적된 손실을 저장할 변수 초기화\n",
    "    train_loss = 0\n",
    "    # 현재까지 맞춘 이미지의 수를 저장할 변수 초기화\n",
    "    train_correct = 0\n",
    "    # 현재까지 학습한 이미지 수를 저장할 변수 초기화\n",
    "    train_cnt = 0\n",
    "\n",
    "    # 배치 단위로 나눈 학습 데이터 순회하며 불러와서\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # 입력 이미지, 라벨 정보를 GPU를 사용하기 위해 to.device()사용\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 학습 전, 이전 학습에서 계산된 gradient 값을 0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 모델에 이미지 학습 (forward propagation이 이루어지며, 모델은 입력을 받아 출력값을 계산)\n",
    "        outputs = model(inputs)\n",
    "        # 모델이 예측한 출력값(outputs)과 실제 정답(labels)을 비교하여 손실 값을 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 손실 값의 gradient를 계산(backward propagation이 이루어지며, 손실 함수를 모델의 출력값으로 미분한 gradient 값을 계산)\n",
    "        loss.backward()\n",
    "        # optimization - 계산된 gradient 값을 이용하여 모델의 파라미터를 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 현재 배치에서 계산된 손실 값을 train_loss에 더함\n",
    "        train_loss += loss.item()\n",
    "        # 출력값(outputs) 중에서 가장 큰 값(_)과 그 값이 존재하는 인덱스(predicted)를 반환\n",
    "        _, predicted = outputs.max(1)\n",
    "        # 배치에 포함되어 학습한 이미지의 수를 train_cnt에 더함\n",
    "        train_cnt += labels.size(0)\n",
    "        # 현재 배치에서 맞춘 개수를 train_correct에 더함\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # epoch 단위로 평균 손실 값과 정확도를 계산\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = 100 * train_correct / train_cnt\n",
    "\n",
    "    # 계산한 평균 손실 값과 정확도를 리스트에 추가\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # Test ---------------------------------------------------------------------\n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    # 현재까지 누적된 손실을 저장할 변수 초기화\n",
    "    test_loss = 0\n",
    "    # 현재까지 맞춘 이미지의 수를 저장할 변수 초기화\n",
    "    test_correct = 0\n",
    "    # 현재까지 학습한 이미지 수를 저장할 변수 초기화\n",
    "    test_cnt = 0\n",
    "\n",
    "    # 모델의 gradient가 필요하지 않아 파라미터에 대한 업데이트를 수행하지 않으면서 forward propagation을 수행해 시간 단축\n",
    "    with torch.no_grad():\n",
    "         # 배치 단위로 나눈 테스트 데이터 순회하며 불러와서\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            # 입력 이미지, 라벨 정보를 GPU를 사용하기 위해 to.device()사용\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # 모델에 이미지 학습 (forward propagation이 이루어지며, 모델은 입력을 받아 출력값을 계산)\n",
    "            outputs = model(inputs)\n",
    "            # 모델이 예측한 출력값(outputs)과 실제 정답(labels)을 비교하여 손실 값을 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 현재 배치에서 계산된 손실 값을 test_loss에 더함\n",
    "            test_loss += loss.item()\n",
    "            # 출력값(outputs) 중에서 가장 큰 값(_)과 그 값이 존재하는 인덱스(predicted)를 반환\n",
    "            _, predicted = outputs.max(1)\n",
    "            # 배치에 포함되어 학습한 이미지의 수를 test_cnt에 더함\n",
    "            test_cnt += labels.size(0)\n",
    "            # 현재 배치에서 맞춘 개수를 test_correct에 더함\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # epoch 단위로 평균 손실 값과 정확도를 계산\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100 * test_correct / test_cnt\n",
    "    # 계산한 평균 손실 값과 정확도를 리스트에 추가\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "    # epoch마다 정확도와 손실률 출력\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Test Loss: {:.4f}, Test Acc: {:.2f}%, Time: {:.4f}s'\n",
    "          .format(epoch + 1, num_epochs, train_loss, train_acc, test_loss, test_acc, time.time() - start_time))\n",
    "    if test_loss < best_loss and test_acc < best_acc:\n",
    "        best_loss = test_loss\n",
    "        best_acc = test_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model, 'model_new.pth')\n",
    "    print('Best_Epoch : {}, Best_loss : {}, Best_acc : {}'.format(best_epoch, best_loss, best_acc))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
